{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n-Ps2nkVsBb"
      },
      "source": [
        "# **ğŸ’ğŸ»ğŸ—¨ï¸ğŸ’ğŸ»â€â™‚ï¸ëŒ€í™” ìš”ì•½ Baseline code**\n",
        "> t5 ëª¨ë¸ baseline\n",
        "- T5TokenizerFast, T5ForConditionalGeneration, T5Config ì‚¬ìš©\n",
        "- ì…ì¶œë ¥ ë°ì´í„° ì „ì²˜ë¦¬\n",
        "    - DatasetForTrain, DatasetForVal : item[input_ids], item[attention_mask], item[labels]ë§Œ ë°˜í™˜\n",
        "    - Processor í´ë˜ìŠ¤ì˜ make_input ë©”ì†Œë“œ : dialogueì— prefix ì¶”ê°€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNq_LylZa1ug"
      },
      "source": [
        "## âš™ï¸ ë°ì´í„° ë° í™˜ê²½ì„¤ì •"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjCiuI_V4glr"
      },
      "source": [
        "### 1) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYqDF_-r2ToB"
      },
      "source": [
        "- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œ í›„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zbZ7SU9P2TYN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-10 23:09:14.083712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-10 23:09:14.097513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-10 23:09:14.101757: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-10 23:09:14.111648: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-10 23:09:14.735900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import yaml\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from rouge import Rouge # ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
        "# from transformers import BartForConditionalGeneration, BartConfig\n",
        "# from transformers import T5TokenizerFast, T5ForConditionalGeneration, T5Config\n",
        "# from transformers import Trainer, TrainingArguments\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, PegasusConfig\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "import wandb # ëª¨ë¸ í•™ìŠµ ê³¼ì •ì„ ì†ì‰½ê²Œ Trackingí•˜ê³ , ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qq46k6_CNQn"
      },
      "source": [
        "### 2) Config file ë§Œë“¤ê¸° (ì„ íƒ)\n",
        "- ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ ì •ë³´ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
        "  ë”°ë¼ì„œ, ì½”ë“œ ìƒì—ì„œ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •í•  ìˆ˜ë„ ìˆì§€ë§Œ ë…ë¦½ì ì¸ ë§¤ê°œë³€ìˆ˜ ì •ë³´ íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZOE9TInCQHJ",
        "outputId": "7979ef2d-59ba-4ff5-c8cc-a2582b6369ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = \"google/pegasus-xsum\"\n",
        "# paust/pko-t5-base\n",
        "# lcw99/t5-base-korean-text-summary\n",
        "# noahkim/KoT5_news_summarization\n",
        "# lcw99/t5-large-korean-text-summary\n",
        "\n",
        "# config ì„¤ì •ì— tokenizer ëª¨ë“ˆì´ ì‚¬ìš©ë˜ë¯€ë¡œ ë¯¸ë¦¬ tokenizerë¥¼ ì •ì˜í•´ì¤ë‹ˆë‹¤.\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5vsACJI7CVb8"
      },
      "outputs": [],
      "source": [
        "config_data = {\n",
        "    \"general\": {\n",
        "        \"data_path\": \"../data_en/\", # ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„° ê²½ë¡œë¥¼ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "        \"model_name\": f\"{model_name}\", # ë¶ˆëŸ¬ì˜¬ ëª¨ë¸ì˜ ì´ë¦„ì„ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "        \"output_dir\": \"./\" # ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ ê°’ì„ ì €ì¥í•  ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "    },\n",
        "    \"tokenizer\": {\n",
        "        \"encoder_max_len\": 512, # 1000\n",
        "        \"decoder_max_len\": 100, # 200\n",
        "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
        "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
        "        # íŠ¹ì • ë‹¨ì–´ë“¤ì´ ë¶„í•´ë˜ì–´ tokenizationì´ ìˆ˜í–‰ë˜ì§€ ì•Šë„ë¡ special_tokensì„ ì§€ì •í•´ì¤ë‹ˆë‹¤.\n",
        "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#',\n",
        "                           '#DateOfBirth#', '#SSN#', '#CardNumber#', '#CarNumber#', '#Email#',\n",
        "                           '#Person#', '#Person4#', '#Person5#', '#Person6#', '#Person7#']\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"overwrite_output_dir\": True,\n",
        "        \"num_train_epochs\": 20, # ì›ë˜ 20,50\n",
        "        \"learning_rate\": 1e-5, # 1e-5, optuna: 3e-5\n",
        "        \"per_device_train_batch_size\": 16, # ì›ë˜ 1ë¡œ ë˜ì–´ ìˆì—ˆê³ , Bartì—ì„œëŠ” 16\n",
        "        \"per_device_eval_batch_size\": 32, # ì›ë˜  1,32\n",
        "        \"warmup_ratio\": 0.1,\n",
        "        \"weight_decay\": 0.01, # 0.01 optuna: 0.005\n",
        "        \"lr_scheduler_type\": 'cosine',\n",
        "        \"optim\": 'adamw_torch', # adamw_torch, optuna: adamw_hf\n",
        "        \"gradient_accumulation_steps\": 6, # 1,6\n",
        "        \"evaluation_strategy\": 'epoch',\n",
        "        \"save_strategy\": 'epoch',\n",
        "        \"save_total_limit\": 5, # 6\n",
        "        \"fp16\": True,\n",
        "        \"load_best_model_at_end\": True,\n",
        "        \"seed\": 42,\n",
        "        \"logging_dir\": \"./logs\",\n",
        "        \"logging_strategy\": \"epoch\",\n",
        "        \"predict_with_generate\": True,\n",
        "        \"generation_max_length\": 100, # 100\n",
        "        \"do_train\": True,\n",
        "        \"do_eval\": True,\n",
        "        \"early_stopping_patience\": 5, # 3\n",
        "        \"early_stopping_threshold\": 0, # 0.001,0\n",
        "        \"report_to\": \"wandb\" # (ì„ íƒ) wandbë¥¼ ì‚¬ìš©í•  ë•Œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "    },\n",
        "    # (ì„ íƒ) wandb í™ˆí˜ì´ì§€ì— ê°€ì…í•˜ì—¬ ì–»ì€ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
        "    \"wandb\": {\n",
        "        \"entity\": \"upstage6_doc_classification\",\n",
        "        \"project\": \"baseline_Pegasus\",\n",
        "        \"name\": \"nlp\"\n",
        "    },\n",
        "    \"inference\": {\n",
        "        \"ckt_path\": \"model ckt path\", # ì‚¬ì „ í•™ìŠµì´ ì§„í–‰ëœ ëª¨ë¸ì˜ checkpoint ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "        \"result_path\": \"./prediction/\",\n",
        "        \"no_repeat_ngram_size\": 2,\n",
        "        \"early_stopping\": True,\n",
        "        \"generate_max_length\": 200, # 200 ìƒì„± ìµœëŒ€ ê¸¸ì´\n",
        "        \"num_beams\": 4,\n",
        "        \"batch_size\" : 8, # 16,32\n",
        "        # ì •í™•í•œ ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•´ ì œê±°í•  ë¶ˆí•„ìš”í•œ ìƒì„± í† í°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm7ob25lHBkR"
      },
      "source": [
        "- ì°¸ê³ âœ…    \n",
        ": wandb ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  entity, project, nameë¥¼ ì§€ì •í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. wandb í™ˆí˜ì´ì§€ì— ê°€ì…í•œ í›„ ì–»ì€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì—¬ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "REJybO5UCabF"
      },
      "outputs": [],
      "source": [
        "# ëª¨ë¸ì˜ êµ¬ì„± ì •ë³´ë¥¼ YAML íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "config_path = \"./config.yaml\"\n",
        "with open(config_path, \"w\") as file:\n",
        "    yaml.dump(config_data, file, allow_unicode=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObEASD6Wj6pl"
      },
      "source": [
        "### 3) Configuration ë¶ˆëŸ¬ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JUBm_6RqlYpV",
        "outputId": "f2d87281-b9ca-492a-b43a-b3613188345f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'general': {'data_path': '../data_en/',\n",
            "             'model_name': 'google/pegasus-xsum',\n",
            "             'output_dir': './'},\n",
            " 'inference': {'batch_size': 8,\n",
            "               'ckt_path': 'model ckt path',\n",
            "               'early_stopping': True,\n",
            "               'generate_max_length': 200,\n",
            "               'no_repeat_ngram_size': 2,\n",
            "               'num_beams': 4,\n",
            "               'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'],\n",
            "               'result_path': './prediction/'},\n",
            " 'tokenizer': {'bos_token': 'None',\n",
            "               'decoder_max_len': 100,\n",
            "               'encoder_max_len': 512,\n",
            "               'eos_token': '</s>',\n",
            "               'special_tokens': ['#Person1#',\n",
            "                                  '#Person2#',\n",
            "                                  '#Person3#',\n",
            "                                  '#PhoneNumber#',\n",
            "                                  '#Address#',\n",
            "                                  '#PassportNumber#',\n",
            "                                  '#DateOfBirth#',\n",
            "                                  '#SSN#',\n",
            "                                  '#CardNumber#',\n",
            "                                  '#CarNumber#',\n",
            "                                  '#Email#',\n",
            "                                  '#Person#',\n",
            "                                  '#Person4#',\n",
            "                                  '#Person5#',\n",
            "                                  '#Person6#',\n",
            "                                  '#Person7#']},\n",
            " 'training': {'do_eval': True,\n",
            "              'do_train': True,\n",
            "              'early_stopping_patience': 5,\n",
            "              'early_stopping_threshold': 0,\n",
            "              'evaluation_strategy': 'epoch',\n",
            "              'fp16': True,\n",
            "              'generation_max_length': 100,\n",
            "              'gradient_accumulation_steps': 6,\n",
            "              'learning_rate': 1e-05,\n",
            "              'load_best_model_at_end': True,\n",
            "              'logging_dir': './logs',\n",
            "              'logging_strategy': 'epoch',\n",
            "              'lr_scheduler_type': 'cosine',\n",
            "              'num_train_epochs': 20,\n",
            "              'optim': 'adamw_torch',\n",
            "              'overwrite_output_dir': True,\n",
            "              'per_device_eval_batch_size': 32,\n",
            "              'per_device_train_batch_size': 16,\n",
            "              'predict_with_generate': True,\n",
            "              'report_to': 'wandb',\n",
            "              'save_strategy': 'epoch',\n",
            "              'save_total_limit': 5,\n",
            "              'seed': 42,\n",
            "              'warmup_ratio': 0.1,\n",
            "              'weight_decay': 0.01},\n",
            " 'wandb': {'entity': 'upstage6_doc_classification',\n",
            "           'name': 'nlp',\n",
            "           'project': 'baseline_Pegasus'}}\n"
          ]
        }
      ],
      "source": [
        "# ì €ì¥ëœ config íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "config_path = \"./config.yaml\"\n",
        "\n",
        "with open(config_path, \"r\") as file:\n",
        "    loaded_config = yaml.safe_load(file)\n",
        "\n",
        "# ë¶ˆëŸ¬ì˜¨ config íŒŒì¼ì˜ ì „ì²´ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "pprint(loaded_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xRSbKEVslhwO",
        "outputId": "14aba3e0-2764-4465-8b40-8c140f07a28d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data_path': '../data_en/',\n",
              " 'model_name': 'google/pegasus-xsum',\n",
              " 'output_dir': './'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ì‹¤í—˜ì— ì“°ì¼ ë°ì´í„°ì˜ ê²½ë¡œ, ì‚¬ìš©ë  ëª¨ë¸, ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ ê²°ê³¼ë¥¼ ì €ì¥í•  ê²½ë¡œì— ëŒ€í•´ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "loaded_config['general']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wyry1f8brKUX"
      },
      "outputs": [],
      "source": [
        "# ì´ê³³ì— ì‚¬ìš©ìê°€ ì €ì¥í•œ ë°ì´í„° dir ì„¤ì •í•˜ê¸°\n",
        "# loaded_config['general']['data_path'] = \"data_path\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1pvFmIOqljv1",
        "outputId": "f5876ac2-d340-4db5-d2eb-dac59b650e43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bos_token': 'None',\n",
              " 'decoder_max_len': 100,\n",
              " 'encoder_max_len': 512,\n",
              " 'eos_token': '</s>',\n",
              " 'special_tokens': ['#Person1#',\n",
              "  '#Person2#',\n",
              "  '#Person3#',\n",
              "  '#PhoneNumber#',\n",
              "  '#Address#',\n",
              "  '#PassportNumber#',\n",
              "  '#DateOfBirth#',\n",
              "  '#SSN#',\n",
              "  '#CardNumber#',\n",
              "  '#CarNumber#',\n",
              "  '#Email#',\n",
              "  '#Person#',\n",
              "  '#Person4#',\n",
              "  '#Person5#',\n",
              "  '#Person6#',\n",
              "  '#Person7#']}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•˜ê¸° ìœ„í•´ tokenization ê³¼ì •ì—ì„œ í•„ìš”í•œ ì •ë³´ë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "loaded_config['tokenizer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEvwCIBVll-h",
        "outputId": "180dae12-b9b4-4b21-dcca-329d2f4f239d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'do_eval': True,\n",
              " 'do_train': True,\n",
              " 'early_stopping_patience': 5,\n",
              " 'early_stopping_threshold': 0,\n",
              " 'evaluation_strategy': 'epoch',\n",
              " 'fp16': True,\n",
              " 'generation_max_length': 100,\n",
              " 'gradient_accumulation_steps': 6,\n",
              " 'learning_rate': 1e-05,\n",
              " 'load_best_model_at_end': True,\n",
              " 'logging_dir': './logs',\n",
              " 'logging_strategy': 'epoch',\n",
              " 'lr_scheduler_type': 'cosine',\n",
              " 'num_train_epochs': 20,\n",
              " 'optim': 'adamw_torch',\n",
              " 'overwrite_output_dir': True,\n",
              " 'per_device_eval_batch_size': 32,\n",
              " 'per_device_train_batch_size': 16,\n",
              " 'predict_with_generate': True,\n",
              " 'report_to': 'wandb',\n",
              " 'save_strategy': 'epoch',\n",
              " 'save_total_limit': 5,\n",
              " 'seed': 42,\n",
              " 'warmup_ratio': 0.1,\n",
              " 'weight_decay': 0.01}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ëª¨ë¸ì´ í›ˆë ¨ ì‹œ ì ìš©ë  ë§¤ê°œë³€ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "loaded_config['training']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhqHf1njlnyg",
        "outputId": "d372c951-e6e4-4ed2-acc2-177ab9bba2a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'entity': 'upstage6_doc_classification',\n",
              " 'name': 'nlp',\n",
              " 'project': 'baseline_Pegasus'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ëª¨ë¸ í•™ìŠµ ê³¼ì •ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ëŠ” wandb ì„¤ì • ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "loaded_config['wandb']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "REV6GsQarKUX"
      },
      "outputs": [],
      "source": [
        "# (ì„ íƒ) ì´ê³³ì— ì‚¬ìš©ìê°€ ì‚¬ìš©í•  wandb config ì„¤ì •\n",
        "# loaded_config['wandb']['entity'] = \"ì‚¬ìš©í•  wandb repo name\"\n",
        "# loaded_config['wandb']['name'] = \"ì‚¬ìš©í•  wandb runì˜ name\"\n",
        "# loaded_config['wandb']['project'] = \"ì‚¬ìš©í•  wandb project name\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm4gxPRVlppj",
        "outputId": "c75aac94-7bfc-4421-9687-53c5d01d35a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch_size': 8,\n",
              " 'ckt_path': 'model ckt path',\n",
              " 'early_stopping': True,\n",
              " 'generate_max_length': 200,\n",
              " 'no_repeat_ngram_size': 2,\n",
              " 'num_beams': 4,\n",
              " 'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'],\n",
              " 'result_path': './prediction/'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ëª¨ë¸ì´ ìµœì¢… ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•œ ë§¤ê°œë³€ìˆ˜ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "loaded_config['inference']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2zt0b-8ogCL"
      },
      "source": [
        "### 4) ë°ì´í„° ë¶ˆëŸ¬ì™€ì„œ í™•ì¸í•´ë³´ê¸°\n",
        "- ì‹¤í—˜ì—ì„œ ì“°ì¼ ë°ì´í„°ë¥¼ loadí•˜ì—¬ ë°ì´í„°ì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "- Train, dev, test ìˆœì„œëŒ€ë¡œ 12457, 499, 250ê°œ ì”© ë°ì´í„°ê°€ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "QFHIE2G04y-K",
        "outputId": "ea276d53-af44-473c-f89d-c606a212d048"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12455</th>\n",
              "      <td>train_12455</td>\n",
              "      <td>#Person1#: Excuse me. You are Mr. Green from M...</td>\n",
              "      <td>Tan Ling picks Mr. Green up who is easily reco...</td>\n",
              "      <td>pick up someone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12456</th>\n",
              "      <td>train_12456</td>\n",
              "      <td>#Person1#: Mister Ewing said we should show up...</td>\n",
              "      <td>#Person1# and #Person2# plan to take the under...</td>\n",
              "      <td>conference center</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12457</th>\n",
              "      <td>train_12457</td>\n",
              "      <td>#Person1#: How can I help you today?\\n#Person2...</td>\n",
              "      <td>#Person2# rents a small car for 5 days with th...</td>\n",
              "      <td>rent a car</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12458</th>\n",
              "      <td>train_12458</td>\n",
              "      <td>#Person1#: You look a bit unhappy today. What'...</td>\n",
              "      <td>#Person2#'s mom lost her job. #Person2# hopes ...</td>\n",
              "      <td>job losing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459</th>\n",
              "      <td>train_12459</td>\n",
              "      <td>#Person1#: Mom, I'm flying to visit uncle Lee'...</td>\n",
              "      <td>#Person1# asks for #Person2#'s idea of packing...</td>\n",
              "      <td>baggage pack</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id                                           dialogue  \\\n",
              "12455  train_12455  #Person1#: Excuse me. You are Mr. Green from M...   \n",
              "12456  train_12456  #Person1#: Mister Ewing said we should show up...   \n",
              "12457  train_12457  #Person1#: How can I help you today?\\n#Person2...   \n",
              "12458  train_12458  #Person1#: You look a bit unhappy today. What'...   \n",
              "12459  train_12459  #Person1#: Mom, I'm flying to visit uncle Lee'...   \n",
              "\n",
              "                                                 summary              topic  \n",
              "12455  Tan Ling picks Mr. Green up who is easily reco...    pick up someone  \n",
              "12456  #Person1# and #Person2# plan to take the under...  conference center  \n",
              "12457  #Person2# rents a small car for 5 days with th...         rent a car  \n",
              "12458  #Person2#'s mom lost her job. #Person2# hopes ...         job losing  \n",
              "12459  #Person1# asks for #Person2#'s idea of packing...       baggage pack  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# configì— ì €ì¥ëœ ë°ì´í„° ê²½ë¡œë¥¼ í†µí•´ trainê³¼ validation dataë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "data_path = loaded_config['general']['data_path']\n",
        "\n",
        "# train dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "train_df = pd.read_csv(os.path.join(data_path,'train_en.csv'))\n",
        "train_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "FAGaYvNZ09Sq",
        "outputId": "cc0ae6d8-a688-4c88-aa8f-d7c4333af561"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>dev_495</td>\n",
              "      <td>#Person1#: Now that it's the new year, I've de...</td>\n",
              "      <td>#Person1# decides to stop smoking and come out...</td>\n",
              "      <td>the new year</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>dev_496</td>\n",
              "      <td>#Person1#: You married Joe, didn't you? \\n#Per...</td>\n",
              "      <td>#Person1# thought #Person2# married Joe. #Pers...</td>\n",
              "      <td>fall in love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>dev_497</td>\n",
              "      <td>#Person1#: How can I help you mam?\\n#Person2#:...</td>\n",
              "      <td>#Person2#'s car makes noises. #Person1# thinks...</td>\n",
              "      <td>noises</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>dev_498</td>\n",
              "      <td>#Person1#: Hello, Amazon's customer service. H...</td>\n",
              "      <td>#Person2# calls Amazon's customer service beca...</td>\n",
              "      <td>a missing page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>dev_499</td>\n",
              "      <td>#Person1#: I can't believe it's almost summer....</td>\n",
              "      <td>#Person2# tells #Person1# #Person2# is going t...</td>\n",
              "      <td>summer vacation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                           dialogue  \\\n",
              "495  dev_495  #Person1#: Now that it's the new year, I've de...   \n",
              "496  dev_496  #Person1#: You married Joe, didn't you? \\n#Per...   \n",
              "497  dev_497  #Person1#: How can I help you mam?\\n#Person2#:...   \n",
              "498  dev_498  #Person1#: Hello, Amazon's customer service. H...   \n",
              "499  dev_499  #Person1#: I can't believe it's almost summer....   \n",
              "\n",
              "                                               summary            topic  \n",
              "495  #Person1# decides to stop smoking and come out...     the new year  \n",
              "496  #Person1# thought #Person2# married Joe. #Pers...     fall in love  \n",
              "497  #Person2#'s car makes noises. #Person1# thinks...           noises  \n",
              "498  #Person2# calls Amazon's customer service beca...   a missing page  \n",
              "499  #Person2# tells #Person1# #Person2# is going t...  summer vacation  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# validation dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "val_df = pd.read_csv(os.path.join(data_path,'validation_en.csv'))\n",
        "val_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>test_498_2</td>\n",
              "      <td>#Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...</td>\n",
              "      <td>Matthew and Steve meet after a long time. Stev...</td>\n",
              "      <td>finding a house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>test_498_3</td>\n",
              "      <td>#Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...</td>\n",
              "      <td>Steve has been looking for a place to live. Ma...</td>\n",
              "      <td>find a house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>test_499_1</td>\n",
              "      <td>#Person1#: Hey, Betsy, did you hear the great ...</td>\n",
              "      <td>Frank invites Besty to the party to celebrate ...</td>\n",
              "      <td>party invitation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>test_499_2</td>\n",
              "      <td>#Person1#: Hey, Betsy, did you hear the great ...</td>\n",
              "      <td>Frank invites Betsy to the big promotion party...</td>\n",
              "      <td>promotion party invitation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>test_499_3</td>\n",
              "      <td>#Person1#: Hey, Betsy, did you hear the great ...</td>\n",
              "      <td>Frank invites Betsy to his party for his promo...</td>\n",
              "      <td>party invitation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id                                           dialogue  \\\n",
              "1495  test_498_2  #Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...   \n",
              "1496  test_498_3  #Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...   \n",
              "1497  test_499_1  #Person1#: Hey, Betsy, did you hear the great ...   \n",
              "1498  test_499_2  #Person1#: Hey, Betsy, did you hear the great ...   \n",
              "1499  test_499_3  #Person1#: Hey, Betsy, did you hear the great ...   \n",
              "\n",
              "                                                summary  \\\n",
              "1495  Matthew and Steve meet after a long time. Stev...   \n",
              "1496  Steve has been looking for a place to live. Ma...   \n",
              "1497  Frank invites Besty to the party to celebrate ...   \n",
              "1498  Frank invites Betsy to the big promotion party...   \n",
              "1499  Frank invites Betsy to his party for his promo...   \n",
              "\n",
              "                           topic  \n",
              "1495             finding a house  \n",
              "1496                find a house  \n",
              "1497            party invitation  \n",
              "1498  promotion party invitation  \n",
              "1499            party invitation  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "test_df = pd.read_csv(os.path.join(data_path,'test_en.csv'))\n",
        "test_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IIaIrpH4kWo"
      },
      "source": [
        "## 1. ë°ì´í„° ê°€ê³µ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ êµ¬ì¶•\n",
        "- csv file ì„ ë¶ˆëŸ¬ì™€ì„œ encoder ì™€ decoderì˜ ì…ë ¥í˜•íƒœë¡œ ê°€ê³µí•´ì¤ë‹ˆë‹¤.\n",
        "- ê°€ê³µëœ ë°ì´í„°ë¥¼ torch dataset class ë¡œ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oWPawUUflwHa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "class Preprocess:\n",
        "    def __init__(self,\n",
        "            bos_token: str,\n",
        "            eos_token: str,\n",
        "        ) -> None:\n",
        "\n",
        "        self.bos_token = bos_token\n",
        "        self.eos_token = eos_token\n",
        "\n",
        "    @staticmethod\n",
        "    # ì‹¤í—˜ì— í•„ìš”í•œ ì»¬ëŸ¼ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "    def make_set_as_df(file_path, is_train=True):\n",
        "        df = pd.read_csv(file_path)\n",
        "        if is_train:\n",
        "            return df[['id', 'dialogue', 'summary']]\n",
        "        else:\n",
        "            return df[['id', 'dialogue']]\n",
        "\n",
        "    # Pegasus ëª¨ë¸ì˜ ì…ë ¥, ì¶œë ¥ í˜•íƒœë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "    def make_input(self, dataset, is_train=True):\n",
        "        prefix = \"summarize: \"\n",
        "        \n",
        "        # ì¸ì½”ë” ì…ë ¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "        encoder_input = dataset['dialogue'].apply(lambda x: prefix + str(x))\n",
        "\n",
        "        if is_train:\n",
        "            # ë””ì½”ë” ì…ë ¥: BOS + summary\n",
        "            decoder_input = dataset['summary'].apply(lambda x: self.bos_token + \" \" + str(x))\n",
        "            \n",
        "            # ë””ì½”ë” ì¶œë ¥: summary + EOS\n",
        "            decoder_output = dataset['summary'].apply(lambda x: str(x) + self.eos_token)\n",
        "            \n",
        "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()\n",
        "        else:\n",
        "            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì¸ ê²½ìš° ë””ì½”ë” ì…ë ¥ì— BOSë§Œ ë„£ì–´ì¤ë‹ˆë‹¤.\n",
        "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
        "            return encoder_input.tolist(), list(decoder_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6GDvodoF8sED"
      },
      "outputs": [],
      "source": [
        "# Trainì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "class DatasetForTrain(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input, labels): # len ì‚­ì œ í›„ \n",
        "        self.encoder_input = encoder_input\n",
        "        self.decoder_input = decoder_input\n",
        "        self.labels = labels\n",
        "        self.len = len(encoder_input['input_ids']) # ë°ì´í„° ê¸¸ì´ ìë™ ê³„ì‚°\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # ì¸ì½”ë” ì¸í’‹ ì²˜ë¦¬ \n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} \n",
        "        # ë””ì½”ë” ì¸í’‹ ì²˜ë¦¬ \n",
        "        item['decoder_input_ids'] = item['input_ids']\n",
        "        # labels ì²˜ë¦¬ (ë³´í†µ ì¸ì½”ë” ì¸í’‹ê³¼ ê°™ê±°ë‚˜ ì¼ë¶€ padding ê°’ì„ -100ìœ¼ë¡œ ì„¤ì •)\n",
        "        labels=self.labels['input_ids'][idx].clone().detach()\n",
        "        labels[labels == 0] = -100 # íŒ¨ë”© ê°’ ë¬´ì‹œ \n",
        "        item['labels'] = labels \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# Validationì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "class DatasetForVal(Dataset):\n",
        "    def __init__(self, encoder_input, labels):\n",
        "        self.encoder_input = encoder_input\n",
        "        # í•™ìŠµì²˜ëŸ¼ decoder_input_idsëŠ” í•„ìš” ì—†ìŒ\n",
        "        self.labels = labels\n",
        "        self.len = len(encoder_input['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} \n",
        "        labels=self.labels['input_ids'][idx].clone().detach()\n",
        "        labels[labels == 0] = -100 # íŒ¨ë”© ê°’ ë¬´ì‹œ \n",
        "        item['labels'] = labels\n",
        "        \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# Testì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "class DatasetForInference(Dataset):\n",
        "    def __init__(self, encoder_input):\n",
        "        self.encoder_input = encoder_input\n",
        "        self.len = len(encoder_input['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Encoder Input ì²˜ë¦¬\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
        "        \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hT9z4vvS2CCb"
      },
      "outputs": [],
      "source": [
        "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ë°ì´í„°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
        "    train_file_path = os.path.join(data_path, 'train_en.csv')\n",
        "    val_file_path = os.path.join(data_path, 'validation_en.csv')\n",
        "\n",
        "    # train, validationì— ëŒ€í•´ ê°ê° ë°ì´í„°í”„ë ˆì„ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
        "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
        "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
        "\n",
        "    # ì¸ì½”ë”ì™€ ë””ì½”ë” ì…ë ¥ ë° ì¶œë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "    encoder_input_train, decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
        "    encoder_input_val, decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
        "\n",
        "    # Train ë°ì´í„°ì…‹ì˜ Tokenization\n",
        "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
        "                                         truncation=True, max_length=config['tokenizer']['encoder_max_len'])\n",
        "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
        "                                         truncation=True, max_length=config['tokenizer']['decoder_max_len'])\n",
        "    tokenized_decoder_outputs = tokenizer(text_target=decoder_output_train, return_tensors=\"pt\", padding=True,\n",
        "                                          truncation=True, max_length=config['tokenizer']['decoder_max_len'])\n",
        "\n",
        "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_outputs, len(encoder_input_train))\n",
        "\n",
        "    # Validation ë°ì´í„°ì…‹ì˜ Tokenization (decoder_input ì—†ì´ ì²˜ë¦¬)\n",
        "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
        "                                             truncation=True, max_length=config['tokenizer']['encoder_max_len'])\n",
        "    val_tokenized_decoder_outputs = tokenizer(text_target=decoder_output_val, return_tensors=\"pt\", padding=True,\n",
        "                                              truncation=True, max_length=config['tokenizer']['decoder_max_len'])\n",
        "\n",
        "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_outputs)\n",
        "\n",
        "    return train_inputs_dataset, val_inputs_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5sKIJ5K5Pz1"
      },
      "source": [
        "## 2. Trainer ë° Trainingargs êµ¬ì¶•í•˜ê¸°\n",
        "- Huggingface ì˜ Trainer ì™€ Training argumentsë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ì¼ê´„ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aQk8ILcEeGNz"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "# from rouge import Rouge\n",
        "\n",
        "def compute_metrics(config, tokenizer, pred):\n",
        "    rouge = Rouge()\n",
        "    predictions = pred.predictions\n",
        "    labels = pred.label_ids\n",
        "\n",
        "    # íŒ¨ë”© í† í°ìœ¼ë¡œ ëŒ€ì²´\n",
        "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
        "    labels[labels == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # ë””ì½”ë”©ëœ ì˜ˆì¸¡ê°’ê³¼ ë ˆì´ë¸”\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    # ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±°\n",
        "    remove_tokens = config['inference']['remove_tokens']\n",
        "    replaced_predictions = decoded_preds.copy()\n",
        "    replaced_labels = decoded_labels.copy()\n",
        "    \n",
        "    for token in remove_tokens:\n",
        "        # ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ê²½ìš°ì˜ ë¶ˆí•„ìš”í•œ í† í°ì„ ì²˜ë¦¬\n",
        "        replaced_predictions = [re.sub(rf\"\\b{token}\\b\", \" \", sentence) for sentence in replaced_predictions]\n",
        "        replaced_labels = [re.sub(rf\"\\b{token}\\b\", \" \", sentence) for sentence in replaced_labels]\n",
        "\n",
        "    # ì¤‘ë³µëœ ê³µë°± ì œê±°\n",
        "    replaced_predictions = [\" \".join(sentence.split()) for sentence in replaced_predictions]\n",
        "    replaced_labels = [\" \".join(sentence.split()) for sentence in replaced_labels]\n",
        "\n",
        "    # ë””ë²„ê¹…ìš© ì¶œë ¥ (í•„ìš” ì‹œ ë¡œê¹…ìœ¼ë¡œ êµì²´ ê°€ëŠ¥)\n",
        "    print('-'*150)\n",
        "    print(f\"PRED: {replaced_predictions[0]}\")\n",
        "    print(f\"GOLD: {replaced_labels[0]}\")\n",
        "    print('-'*150)\n",
        "    print(f\"PRED: {replaced_predictions[1]}\")\n",
        "    print(f\"GOLD: {replaced_labels[1]}\")\n",
        "    print('-'*150)\n",
        "    print(f\"PRED: {replaced_predictions[2]}\")\n",
        "    print(f\"GOLD: {replaced_labels[2]}\")\n",
        "\n",
        "    # ROUGE ì ìˆ˜ ê³„ì‚°\n",
        "    results = rouge.get_scores(replaced_predictions, replaced_labels, avg=True)\n",
        "\n",
        "    # F1-scoreë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€\n",
        "    result = {key: value[\"f\"] for key, value in results.items()}\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RInkG8g-HjBi"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµì„ ìœ„í•œ trainer í´ë˜ìŠ¤ì™€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "def load_trainer_for_train(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset):\n",
        "    print('-'*10, 'Make training arguments', '-'*10,)\n",
        "    # set training args\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "                output_dir=config['general']['output_dir'], # model output directory\n",
        "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
        "                num_train_epochs=config['training']['num_train_epochs'],  # total number of training epochs\n",
        "                learning_rate=config['training']['learning_rate'], # learning_rate\n",
        "                per_device_train_batch_size=config['training']['per_device_train_batch_size'], # batch size per device during training\n",
        "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],# batch size for evaluation\n",
        "                warmup_ratio=config['training']['warmup_ratio'],  # number of warmup steps for learning rate scheduler\n",
        "                weight_decay=config['training']['weight_decay'],  # strength of weight decay\n",
        "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
        "                optim =config['training']['optim'],\n",
        "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
        "                evaluation_strategy=config['training']['evaluation_strategy'], # evaluation strategy to adopt during training\n",
        "                save_strategy =config['training']['save_strategy'],\n",
        "                save_total_limit=config['training']['save_total_limit'], # number of total save model.\n",
        "                fp16=config['training']['fp16'],\n",
        "                load_best_model_at_end=config['training']['load_best_model_at_end'], # ìµœì¢…ì ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ì ìˆ˜ ì €ì¥\n",
        "                seed=config['training']['seed'],\n",
        "                logging_dir=config['training']['logging_dir'], # directory for storing logs\n",
        "                logging_strategy=config['training']['logging_strategy'],\n",
        "                predict_with_generate=config['training']['predict_with_generate'], #To use BLEU or ROUGE score\n",
        "                generation_max_length=config['training']['generation_max_length'],\n",
        "                do_train=config['training']['do_train'],\n",
        "                do_eval=config['training']['do_eval'],\n",
        "                report_to=config['training']['report_to'] # (ì„ íƒ) wandbë¥¼ ì‚¬ìš©í•  ë•Œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "            )\n",
        "\n",
        "    # (ì„ íƒ) ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ì„ ì¶”ì í•˜ëŠ” wandbë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì´ˆê¸°í™” í•´ì¤ë‹ˆë‹¤.\n",
        "    wandb.init(\n",
        "        entity=config['wandb']['entity'],\n",
        "        project=config['wandb']['project'],\n",
        "        name=config['wandb']['name'],\n",
        "    )\n",
        "\n",
        "    # (ì„ íƒ) ëª¨ë¸ checkpointë¥¼ wandbì— ì €ì¥í•˜ë„ë¡ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "    os.environ[\"WANDB_LOG_MODEL\"]=\"end\"\n",
        "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
        "    \n",
        "    # Validation lossê°€ ë” ì´ìƒ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ í•™ìŠµì„ ì¤‘ë‹¨ì‹œí‚¤ëŠ” EarlyStopping ê¸°ëŠ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "    MyCallback = EarlyStoppingCallback(\n",
        "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
        "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
        "    )\n",
        "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
        "    print('-'*10, 'Make trainer', '-'*10,)\n",
        "\n",
        "    # Trainer í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=generate_model, # ì‚¬ìš©ìê°€ ì‚¬ì „ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ëª¨ë¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
        "        args=training_args,\n",
        "        train_dataset=train_inputs_dataset,\n",
        "        eval_dataset=val_inputs_dataset,\n",
        "        compute_metrics = lambda pred: compute_metrics(config, tokenizer, pred),\n",
        "        callbacks = [MyCallback]\n",
        "    )\n",
        "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
        "\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KKWHe8dE5fSx"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµì„ ìœ„í•œ tokenizerì™€ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "def load_tokenizer_and_model_for_train(config, device):\n",
        "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
        "    print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
        "\n",
        "    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì´ë¦„ \n",
        "    model_name = config['general']['model_name']\n",
        "\n",
        "    # ëª¨ë¸ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    model_config = PegasusConfig.from_pretrained(model_name)\n",
        "\n",
        "    # í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Special tokens ì¶”ê°€ \n",
        "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
        "    tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "    # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì„¤ì • ì ìš©\n",
        "    generate_model = PegasusForConditionalGeneration.from_pretrained(config['general']['model_name'], config=model_config)\n",
        "    \n",
        "    # í† í¬ë‚˜ì´ì €ì— ìƒˆë¡œìš´ í† í°ì´ ì¶”ê°€ë˜ì—ˆìœ¼ë¯€ë¡œ ì„ë² ë”© í¬ê¸° ì¬ì¡°ì • \n",
        "    generate_model.resize_token_embeddings(len(tokenizer)) \n",
        "\n",
        "    # GPU or CPU\n",
        "    generate_model.to(device)\n",
        "\n",
        "    # ëª¨ë¸ êµ¬ì„± ì •ë³´ ì¶œë ¥\n",
        "    print('-'*10,'Model Configuration','-'*10)\n",
        "    print(generate_model.config)\n",
        "\n",
        "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
        "    return generate_model , tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvutzKQYvQgl"
      },
      "source": [
        "## 3. ëª¨ë¸ í•™ìŠµí•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImZUb-BC42J-"
      },
      "source": [
        "- ì•ì—ì„œ êµ¬ì¶•í•œ í´ë˜ìŠ¤ ë° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qnA96wmR44is"
      },
      "outputs": [],
      "source": [
        "def main(config):\n",
        "    try:\n",
        "        # ì‚¬ìš©í•  deviceë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
        "        print('-'*10, f'device : {device}', '-'*10,)\n",
        "        print(torch.__version__)\n",
        "\n",
        "        # ì‚¬ìš©í•  ëª¨ë¸ê³¼ tokenizerë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "        generate_model, tokenizer = load_tokenizer_and_model_for_train(config, device)\n",
        "        print('-'*10,\"tokenizer special tokens : \", tokenizer.special_tokens_map,'-'*10)\n",
        "        print('-'*10,\"additional special tokens : \", tokenizer.additional_special_tokens, tokenizer.additional_special_tokens_ids)\n",
        "\n",
        "        # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "        preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
        "        data_path = config['general']['data_path']\n",
        "        train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config, preprocessor, data_path, tokenizer)\n",
        "\n",
        "        # # Clear the cache to free up GPU memory\n",
        "        # torch.cuda.empty_cache()\n",
        "\n",
        "        # Trainer í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "        trainer = load_trainer_for_train(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset)\n",
        "        trainer.train()   # ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training:{e}\")\n",
        "    finally: \n",
        "        print('-'*10,'Training finished.CLosing WandB session','-'*10)\n",
        "\n",
        "    # (ì„ íƒ) ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œëœ í›„ wandbë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1DMS60wL-Dhv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- device : cuda:0 ----------\n",
            "2.4.1+cu121\n",
            "---------- Load tokenizer & model ----------\n",
            "---------- Model Name : google/pegasus-xsum ----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbda6f43da7a4c428a55ab48003ef974",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc6a502632bc481d943dd0f5b432801d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- Model Configuration ----------\n",
            "PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-xsum\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 0,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.6,\n",
            "  \"max_length\": 64,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96119\n",
            "}\n",
            "\n",
            "---------- Load tokenizer & model complete ----------\n",
            "---------- tokenizer special tokens :  {'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask_2>', 'additional_special_tokens': ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#', '#DateOfBirth#', '#SSN#', '#CardNumber#', '#CarNumber#', '#Email#', '#Person#', '#Person4#', '#Person5#', '#Person6#', '#Person7#']} ----------\n",
            "---------- additional special tokens :  ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#', '#DateOfBirth#', '#SSN#', '#CardNumber#', '#CarNumber#', '#Email#', '#Person#', '#Person4#', '#Person5#', '#Person6#', '#Person7#'] [96103, 96104, 96105, 96106, 96107, 96108, 96109, 96110, 96111, 96112, 96113, 96114, 96115, 96116, 96117, 96118]\n",
            "Error during training:DatasetForTrain.__init__() takes 4 positional arguments but 5 were given\n",
            "---------- Training finished.CLosing WandB session ----------\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main(loaded_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFtWqowCGzEc"
      },
      "source": [
        "## 4. ëª¨ë¸ ì¶”ë¡ í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEDwgCnarKUZ"
      },
      "outputs": [],
      "source": [
        "# ì¶”ë¡ ì— ì‚¬ìš©í•  ckt ê²½ë¡œ ì„¤ì •\n",
        "loaded_config['inference']['ckt_path'] = \"checkpoint-22837\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFGul3-rSscf"
      },
      "source": [
        "- test dataë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV1Do7nlTylG"
      },
      "outputs": [],
      "source": [
        "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ë°ì´í„°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "def prepare_test_dataset(config, preprocessor, tokenizer):\n",
        "\n",
        "    test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
        "\n",
        "    test_data = preprocessor.make_set_as_df(test_file_path, is_train=False)\n",
        "    test_id = test_data['fname']\n",
        "\n",
        "    print('-'*150)\n",
        "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
        "    print('-'*150)\n",
        "\n",
        "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data, is_test=True)\n",
        "    print('-'*10, 'Load data complete', '-'*10,)\n",
        "\n",
        "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
        "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
        "    \n",
        "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
        "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
        "\n",
        "    return test_data, test_encoder_inputs_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb49bLULT3aS"
      },
      "outputs": [],
      "source": [
        "# ì¶”ë¡ ì„ ìœ„í•œ tokenizerì™€ í•™ìŠµì‹œí‚¨ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "def load_tokenizer_and_model_for_test(config, device):\n",
        "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
        "\n",
        "    model_name = config['general']['model_name']\n",
        "    ckt_path = config['inference']['ckt_path']\n",
        "    print('-'*10, f'Model Name : {model_name}', '-'*10,)\n",
        "\n",
        "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
        "    tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "    generate_model = PegasusForConditionalGeneration.from_pretrained(ckt_path)\n",
        "    generate_model.resize_token_embeddings(len(tokenizer))\n",
        "    generate_model.to(device)\n",
        "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
        "\n",
        "    return generate_model , tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axzu9rsoGLgJ"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµëœ ëª¨ë¸ì´ ìƒì„±í•œ ìš”ì•½ë¬¸ì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
        "def inference(config):\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
        "    print('-'*10, f'device : {device}', '-'*10,)\n",
        "    print(torch.__version__)\n",
        "\n",
        "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
        "\n",
        "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
        "\n",
        "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config, preprocessor, tokenizer)\n",
        "   \n",
        "    batch_size=config['inference']['batch_size']\n",
        "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=batch_size)\n",
        "\n",
        "    summary = []\n",
        "    text_ids = []\n",
        "    with torch.no_grad():\n",
        "        for item in tqdm(dataloader):\n",
        "            text_ids.extend(item['ID'])\n",
        "            generated_ids = generate_model.generate(\n",
        "                input_ids=item['input_ids'].to('cuda:0'),\n",
        "                no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
        "                early_stopping=config['inference']['early_stopping'],\n",
        "                max_length=config['inference']['generate_max_length'],\n",
        "                num_beams=config['inference']['num_beams'],\n",
        "            )\n",
        "            for ids in generated_ids:\n",
        "                result = tokenizer.decode(ids,skip_special_tokens=True)\n",
        "                summary.append(result)\n",
        "\n",
        "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•˜ì—¬ ë…¸ì´ì¦ˆì— í•´ë‹¹ë˜ëŠ” ìŠ¤í˜ì…œ í† í°ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
        "    # remove_tokens = config['inference']['remove_tokens']\n",
        "    # preprocessed_summary = summary.copy()\n",
        "    # for token in remove_tokens:\n",
        "    #     preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
        "\n",
        "    output = pd.DataFrame(\n",
        "        {\n",
        "            \"fname\": test_data['fname'],\n",
        "            \"summary\" : summary,\n",
        "        }\n",
        "    )\n",
        "    result_path = config['inference']['result_path']\n",
        "    if not os.path.exists(result_path):\n",
        "        os.makedirs(result_path)\n",
        "    output.to_csv(os.path.join(result_path, \"output_pegasus_en.csv\"), index=False)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pJ1ZXf-5V50",
        "outputId": "ec7f63de-7fc0-4911-cf29-df4c2ae48cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- device : cuda:0 ----------\n",
            "2.1.0\n",
            "---------- Load tokenizer & model ----------\n",
            "---------- Model Name : lcw99/t5-large-korean-text-summary ----------\n",
            "---------- Load tokenizer & model complete ----------\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "test_data:\n",
            "#Person1#: ë”ìŠ¨ ì”¨, ë°›ì•„ì“°ê¸° ì¢€ í•´ì£¼ì„¸ìš”. \n",
            "#Person2#: ë„¤, ì‹¤ì¥ë‹˜...\n",
            "#Person1#: ì´ê²ƒì€ ì˜¤ëŠ˜ ì˜¤í›„ê¹Œì§€ ëª¨ë“  ì§ì›ì—ê²Œ ë‚´ë¶€ ë©”ëª¨ë¡œ ì „ë‹¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì¤€ë¹„ë˜ì…¨ë‚˜ìš”?\n",
            "#Person2#: ë„¤, ì‹¤ì¥ë‹˜. ì‹œì‘í•˜ì…”ë„ ë©ë‹ˆë‹¤.\n",
            "#Person1#: ëª¨ë“  ì§ì›ë“¤ì—ê²Œ ì£¼ì˜í•˜ë¼... ì¦‰ì‹œ íš¨ë ¥ì„ ë°œíœ˜í•˜ì—¬, ëª¨ë“  ì‚¬ë¬´ì‹¤ í†µì‹ ì€ ì´ë©”ì¼ í†µì‹ ê³¼ ê³µì‹ ë©”ëª¨ë¡œ ì œí•œë©ë‹ˆë‹¤. ê·¼ë¬´ ì‹œê°„ ë™ì•ˆ ì§ì›ë“¤ì´ ì¦‰ì‹œ ë©”ì‹œì§€ í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì—„ê²©íˆ ê¸ˆì§€ë©ë‹ˆë‹¤.\n",
            "#Person2#: ì‹¤ì¥ë‹˜, ì´ê²ƒì€ ë‚´ë¶€ í†µì‹ ì—ë§Œ ì ìš©ë˜ëŠ” ê±´ê°€ìš”? ì•„ë‹ˆë©´ ì™¸ë¶€ í†µì‹ ì—ë„ ì œí•œì´ ë˜ëŠ” ê±´ê°€ìš”?\n",
            "#Person1#: ì´ê²ƒì€ ëª¨ë“  í†µì‹ ì— ì ìš©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤, ì´ ì‚¬ë¬´ì‹¤ ë‚´ì˜ ì§ì›ë“¤ ì‚¬ì´ë¿ë§Œ ì•„ë‹ˆë¼ ì™¸ë¶€ í†µì‹ ì—ë„ ë§ˆì°¬ê°€ì§€ì…ë‹ˆë‹¤.\n",
            "#Person2#: í•˜ì§€ë§Œ ì‹¤ì¥ë‹˜, ë§ì€ ì§ì›ë“¤ì´ ê³ ê°ê³¼ ì†Œí†µí•˜ê¸° ìœ„í•´ ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
            "#Person1#: ê·¸ë“¤ì€ ê·¸ë“¤ì˜ ì˜ì‚¬ì†Œí†µ ë°©ë²•ì„ ë°”ê¾¸ì–´ì•¼ë§Œ í•©ë‹ˆë‹¤. ì´ ì‚¬ë¬´ì‹¤ì—ì„œ ëˆ„êµ¬ë„ ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê¸°ë¥¼ ì›í•©ë‹ˆë‹¤. ë„ˆë¬´ ë§ì€ ì‹œê°„ì„ ë‚­ë¹„í•˜ê²Œ ë©ë‹ˆë‹¤! ì´ì œ, ë©”ëª¨ë¥¼ ê³„ì†í•´ì£¼ì„¸ìš”. ìš°ë¦¬ê°€ ì–´ë””ê¹Œì§€ í–ˆë‚˜ìš”?\n",
            "#Person2#: ì´ê²ƒì€ ë‚´ë¶€ì™€ ì™¸ë¶€ í†µì‹ ì— ì ìš©ë©ë‹ˆë‹¤.\n",
            "#Person1#: ê·¸ë ‡ìŠµë‹ˆë‹¤. ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ê³„ì† ì‚¬ìš©í•˜ëŠ” ì–´ë–¤ ì§ì›ì´ë¼ë„ ë¨¼ì € ê²½ê³ ë¥¼ ë°›ê³  ì§ë¬´ ì •ì§€ì— ì²˜í•´ì§ˆ ê²ƒì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ìœ„ë°˜ ì‹œì—ëŠ” ì§ì›ì€ í•´ê³ ì— ì²˜í•´ì§ˆ ê²ƒì…ë‹ˆë‹¤. ì´ ìƒˆë¡œìš´ ì •ì±…ì— ëŒ€í•œ ì–´ë–¤ ì§ˆë¬¸ì´ë¼ë„ ë¶€ì„œì¥ì—ê²Œ ì§ì ‘ ë¬¸ì˜í•˜ë©´ ë©ë‹ˆë‹¤.\n",
            "#Person2#: ê·¸ê²Œ ë‹¤ì‹ ê°€ìš”?\n",
            "#Person1#: ë„¤. ì´ ë©”ëª¨ë¥¼ ì˜¤í›„ 4ì‹œ ì „ì— ëª¨ë“  ì§ì›ì—ê²Œ íƒ€ì´í•‘í•˜ì—¬ ë°°í¬í•´ ì£¼ì„¸ìš”.\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "---------- Load data complete ----------\n",
            "---------- Make dataset complete ----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [04:40<00:00,  2.25s/it]\n"
          ]
        }
      ],
      "source": [
        "# í•™ìŠµëœ ëª¨ë¸ì˜ testë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "if __name__ == \"__main__\":\n",
        "    output = inference(loaded_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsPmLfhbzZqS",
        "outputId": "fd4a2aaf-592a-47a7-95f4-402fcf08882f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>#Person1#ì€ ëª¨ë“  ì§ì›ë“¤ì—ê²Œ ì¦‰ì‹œ ë©”ì‹œì§€ í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>#Person2#ëŠ” êµí†µ ì²´ì¦ì— ê±¸ë ¸ë‹¤. #Person1#ì€ ëŒ€ì¤‘êµí†µì„ ì´ìš©í•˜ëŠ” ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>#Person1#ì€ #Person2#ì—ê²Œ ë§ˆìƒ¤ì™€ íˆì–´ë¡œê°€ ì´í˜¼ì„ ì‹ ì²­í–ˆë‹¤ê³  ë§í•œë‹¤...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>#Person1#ì€ ë¸Œë¼ì´ì–¸ì˜ ìƒì¼ íŒŒí‹°ì— ì°¸ì„í•˜ê³  ê·¸ì™€ ì¶¤ì„ ì¶”ë©° ì¶•í•˜í•œë‹¤.  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>#Person2#ëŠ” #Person1#ì—ê²Œ ì˜¬ë¦¼í”½ ìŠ¤íƒ€ë””ì›€ì´ 6ì›”ì— ì™„ê³µë  ì˜ˆì •ì´ë©°...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>test_495</td>\n",
              "      <td>ì­ì€ ì°°ë¦¬ì—ê²Œ ë¹„ë””ì˜¤ ê²Œì„ì„ í•˜ìê³  ì œì•ˆí•œë‹¤. ì°°ë¦¬ëŠ” ê·¸ê²ƒì´ í¥ë¯¸ë¡­ë‹¤ê³  ìƒê°í•˜ê³  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>test_496</td>\n",
              "      <td>#Person2#ëŠ” #Person1#ì—ê²Œ ì»¨íŠ¸ë¦¬ ìŒì•…ì— ê´€ì‹¬ì„ ê°€ì§€ê²Œ ëœ ê³„ê¸°ì™€ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>test_497</td>\n",
              "      <td>ì•¨ë¦¬ìŠ¤ëŠ” #Person1#ì—ê²Œ ì„¸íƒê¸°ì™€ ê±´ì¡°ê¸°ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œë ¤ì£¼ê³ , ê¸°ê³„...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>test_498</td>\n",
              "      <td>ìŠ¤í‹°ë¸Œê°€ ë§¤íŠœì—ê²Œ ìµœê·¼ì— ì‚´ ê³³ì„ ì°¾ê³  ìˆë‹¤ê³  ë§í•œë‹¤. ê·¸ë“¤ì€ í•¨ê»˜ ë‹¤ìš° ë¶€ì¸ì˜ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>test_499</td>\n",
              "      <td>í”„ë­í¬ëŠ” ìŠ¹ì§„ íŒŒí‹°ì— ë²³ì‹œë¥¼ ì´ˆëŒ€í•˜ê³  ê·¸ë“¤ì€ ì°¸ì„í•  ì˜ˆì •ì´ë‹¤. í”„ë­í¬ì€ ê°€ì¡±ê³¼ì˜ ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>499 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        fname                                            summary\n",
              "0      test_0   #Person1#ì€ ëª¨ë“  ì§ì›ë“¤ì—ê²Œ ì¦‰ì‹œ ë©”ì‹œì§€ í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜...\n",
              "1      test_1   #Person2#ëŠ” êµí†µ ì²´ì¦ì— ê±¸ë ¸ë‹¤. #Person1#ì€ ëŒ€ì¤‘êµí†µì„ ì´ìš©í•˜ëŠ” ...\n",
              "2      test_2   #Person1#ì€ #Person2#ì—ê²Œ ë§ˆìƒ¤ì™€ íˆì–´ë¡œê°€ ì´í˜¼ì„ ì‹ ì²­í–ˆë‹¤ê³  ë§í•œë‹¤...\n",
              "3      test_3   #Person1#ì€ ë¸Œë¼ì´ì–¸ì˜ ìƒì¼ íŒŒí‹°ì— ì°¸ì„í•˜ê³  ê·¸ì™€ ì¶¤ì„ ì¶”ë©° ì¶•í•˜í•œë‹¤.  ...\n",
              "4      test_4   #Person2#ëŠ” #Person1#ì—ê²Œ ì˜¬ë¦¼í”½ ìŠ¤íƒ€ë””ì›€ì´ 6ì›”ì— ì™„ê³µë  ì˜ˆì •ì´ë©°...\n",
              "..        ...                                                ...\n",
              "494  test_495   ì­ì€ ì°°ë¦¬ì—ê²Œ ë¹„ë””ì˜¤ ê²Œì„ì„ í•˜ìê³  ì œì•ˆí•œë‹¤. ì°°ë¦¬ëŠ” ê·¸ê²ƒì´ í¥ë¯¸ë¡­ë‹¤ê³  ìƒê°í•˜ê³  ...\n",
              "495  test_496   #Person2#ëŠ” #Person1#ì—ê²Œ ì»¨íŠ¸ë¦¬ ìŒì•…ì— ê´€ì‹¬ì„ ê°€ì§€ê²Œ ëœ ê³„ê¸°ì™€ ...\n",
              "496  test_497   ì•¨ë¦¬ìŠ¤ëŠ” #Person1#ì—ê²Œ ì„¸íƒê¸°ì™€ ê±´ì¡°ê¸°ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œë ¤ì£¼ê³ , ê¸°ê³„...\n",
              "497  test_498   ìŠ¤í‹°ë¸Œê°€ ë§¤íŠœì—ê²Œ ìµœê·¼ì— ì‚´ ê³³ì„ ì°¾ê³  ìˆë‹¤ê³  ë§í•œë‹¤. ê·¸ë“¤ì€ í•¨ê»˜ ë‹¤ìš° ë¶€ì¸ì˜ ...\n",
              "498  test_499   í”„ë­í¬ëŠ” ìŠ¹ì§„ íŒŒí‹°ì— ë²³ì‹œë¥¼ ì´ˆëŒ€í•˜ê³  ê·¸ë“¤ì€ ì°¸ì„í•  ì˜ˆì •ì´ë‹¤. í”„ë­í¬ì€ ê°€ì¡±ê³¼ì˜ ...\n",
              "\n",
              "[499 rows x 2 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output  # ê° ëŒ€í™”ë¬¸ì— ëŒ€í•œ ìš”ì•½ë¬¸ì´ ì¶œë ¥ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf6Ospc7rKUc",
        "outputId": "e9efb961-c048-447d-867e-69a6f1f72c0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(output['summary'][0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
