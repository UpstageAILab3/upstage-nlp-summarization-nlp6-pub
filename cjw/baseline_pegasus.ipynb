{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n-Ps2nkVsBb"
      },
      "source": [
        "# **💁🏻🗨️💁🏻‍♂️대화 요약 Baseline code**\n",
        "> t5 모델 baseline\n",
        "- T5TokenizerFast, T5ForConditionalGeneration, T5Config 사용\n",
        "- 입출력 데이터 전처리\n",
        "    - DatasetForTrain, DatasetForVal : item[input_ids], item[attention_mask], item[labels]만 반환\n",
        "    - Processor 클래스의 make_input 메소드 : dialogue에 prefix 추가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNq_LylZa1ug"
      },
      "source": [
        "## ⚙️ 데이터 및 환경설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjCiuI_V4glr"
      },
      "source": [
        "### 1) 필요한 라이브러리 설치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYqDF_-r2ToB"
      },
      "source": [
        "- 필요한 라이브러리를 설치한 후 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zbZ7SU9P2TYN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-10 23:09:14.083712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-10 23:09:14.097513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-10 23:09:14.101757: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-10 23:09:14.111648: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-10 23:09:14.735900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import yaml\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
        "\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
        "# from transformers import BartForConditionalGeneration, BartConfig\n",
        "# from transformers import T5TokenizerFast, T5ForConditionalGeneration, T5Config\n",
        "# from transformers import Trainer, TrainingArguments\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, PegasusConfig\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "import wandb # 모델 학습 과정을 손쉽게 Tracking하고, 시각화할 수 있는 라이브러리입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qq46k6_CNQn"
      },
      "source": [
        "### 2) Config file 만들기 (선택)\n",
        "- 모델 생성에 필요한 다양한 매개변수 정보를 저장할 수 있습니다.  \n",
        "  따라서, 코드 상에서 모델의 매개변수를 설정할 수도 있지만 독립적인 매개변수 정보 파일을 생성하여 관리할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZOE9TInCQHJ",
        "outputId": "7979ef2d-59ba-4ff5-c8cc-a2582b6369ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = \"google/pegasus-xsum\"\n",
        "# paust/pko-t5-base\n",
        "# lcw99/t5-base-korean-text-summary\n",
        "# noahkim/KoT5_news_summarization\n",
        "# lcw99/t5-large-korean-text-summary\n",
        "\n",
        "# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5vsACJI7CVb8"
      },
      "outputs": [],
      "source": [
        "config_data = {\n",
        "    \"general\": {\n",
        "        \"data_path\": \"../data_en/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
        "        \"model_name\": f\"{model_name}\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
        "        \"output_dir\": \"./\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
        "    },\n",
        "    \"tokenizer\": {\n",
        "        \"encoder_max_len\": 512, # 1000\n",
        "        \"decoder_max_len\": 100, # 200\n",
        "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
        "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
        "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
        "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#',\n",
        "                           '#DateOfBirth#', '#SSN#', '#CardNumber#', '#CarNumber#', '#Email#',\n",
        "                           '#Person#', '#Person4#', '#Person5#', '#Person6#', '#Person7#']\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"overwrite_output_dir\": True,\n",
        "        \"num_train_epochs\": 20, # 원래 20,50\n",
        "        \"learning_rate\": 1e-5, # 1e-5, optuna: 3e-5\n",
        "        \"per_device_train_batch_size\": 16, # 원래 1로 되어 있었고, Bart에서는 16\n",
        "        \"per_device_eval_batch_size\": 32, # 원래  1,32\n",
        "        \"warmup_ratio\": 0.1,\n",
        "        \"weight_decay\": 0.01, # 0.01 optuna: 0.005\n",
        "        \"lr_scheduler_type\": 'cosine',\n",
        "        \"optim\": 'adamw_torch', # adamw_torch, optuna: adamw_hf\n",
        "        \"gradient_accumulation_steps\": 6, # 1,6\n",
        "        \"evaluation_strategy\": 'epoch',\n",
        "        \"save_strategy\": 'epoch',\n",
        "        \"save_total_limit\": 5, # 6\n",
        "        \"fp16\": True,\n",
        "        \"load_best_model_at_end\": True,\n",
        "        \"seed\": 42,\n",
        "        \"logging_dir\": \"./logs\",\n",
        "        \"logging_strategy\": \"epoch\",\n",
        "        \"predict_with_generate\": True,\n",
        "        \"generation_max_length\": 100, # 100\n",
        "        \"do_train\": True,\n",
        "        \"do_eval\": True,\n",
        "        \"early_stopping_patience\": 5, # 3\n",
        "        \"early_stopping_threshold\": 0, # 0.001,0\n",
        "        \"report_to\": \"wandb\" # (선택) wandb를 사용할 때 설정합니다.\n",
        "    },\n",
        "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
        "    \"wandb\": {\n",
        "        \"entity\": \"upstage6_doc_classification\",\n",
        "        \"project\": \"baseline_Pegasus\",\n",
        "        \"name\": \"nlp\"\n",
        "    },\n",
        "    \"inference\": {\n",
        "        \"ckt_path\": \"model ckt path\", # 사전 학습이 진행된 모델의 checkpoint 경로를 설정합니다.\n",
        "        \"result_path\": \"./prediction/\",\n",
        "        \"no_repeat_ngram_size\": 2,\n",
        "        \"early_stopping\": True,\n",
        "        \"generate_max_length\": 200, # 200 생성 최대 길이\n",
        "        \"num_beams\": 4,\n",
        "        \"batch_size\" : 8, # 16,32\n",
        "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
        "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm7ob25lHBkR"
      },
      "source": [
        "- 참고✅    \n",
        ": wandb 라이브러리를 사용하기 위해선 entity, project, name를 지정해주어야 합니다. wandb 홈페이지에 가입한 후 얻은 정보를 입력하여 작동할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "REJybO5UCabF"
      },
      "outputs": [],
      "source": [
        "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
        "config_path = \"./config.yaml\"\n",
        "with open(config_path, \"w\") as file:\n",
        "    yaml.dump(config_data, file, allow_unicode=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObEASD6Wj6pl"
      },
      "source": [
        "### 3) Configuration 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JUBm_6RqlYpV",
        "outputId": "f2d87281-b9ca-492a-b43a-b3613188345f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'general': {'data_path': '../data_en/',\n",
            "             'model_name': 'google/pegasus-xsum',\n",
            "             'output_dir': './'},\n",
            " 'inference': {'batch_size': 8,\n",
            "               'ckt_path': 'model ckt path',\n",
            "               'early_stopping': True,\n",
            "               'generate_max_length': 200,\n",
            "               'no_repeat_ngram_size': 2,\n",
            "               'num_beams': 4,\n",
            "               'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'],\n",
            "               'result_path': './prediction/'},\n",
            " 'tokenizer': {'bos_token': 'None',\n",
            "               'decoder_max_len': 100,\n",
            "               'encoder_max_len': 512,\n",
            "               'eos_token': '</s>',\n",
            "               'special_tokens': ['#Person1#',\n",
            "                                  '#Person2#',\n",
            "                                  '#Person3#',\n",
            "                                  '#PhoneNumber#',\n",
            "                                  '#Address#',\n",
            "                                  '#PassportNumber#',\n",
            "                                  '#DateOfBirth#',\n",
            "                                  '#SSN#',\n",
            "                                  '#CardNumber#',\n",
            "                                  '#CarNumber#',\n",
            "                                  '#Email#',\n",
            "                                  '#Person#',\n",
            "                                  '#Person4#',\n",
            "                                  '#Person5#',\n",
            "                                  '#Person6#',\n",
            "                                  '#Person7#']},\n",
            " 'training': {'do_eval': True,\n",
            "              'do_train': True,\n",
            "              'early_stopping_patience': 5,\n",
            "              'early_stopping_threshold': 0,\n",
            "              'evaluation_strategy': 'epoch',\n",
            "              'fp16': True,\n",
            "              'generation_max_length': 100,\n",
            "              'gradient_accumulation_steps': 6,\n",
            "              'learning_rate': 1e-05,\n",
            "              'load_best_model_at_end': True,\n",
            "              'logging_dir': './logs',\n",
            "              'logging_strategy': 'epoch',\n",
            "              'lr_scheduler_type': 'cosine',\n",
            "              'num_train_epochs': 20,\n",
            "              'optim': 'adamw_torch',\n",
            "              'overwrite_output_dir': True,\n",
            "              'per_device_eval_batch_size': 32,\n",
            "              'per_device_train_batch_size': 16,\n",
            "              'predict_with_generate': True,\n",
            "              'report_to': 'wandb',\n",
            "              'save_strategy': 'epoch',\n",
            "              'save_total_limit': 5,\n",
            "              'seed': 42,\n",
            "              'warmup_ratio': 0.1,\n",
            "              'weight_decay': 0.01},\n",
            " 'wandb': {'entity': 'upstage6_doc_classification',\n",
            "           'name': 'nlp',\n",
            "           'project': 'baseline_Pegasus'}}\n"
          ]
        }
      ],
      "source": [
        "# 저장된 config 파일을 불러옵니다.\n",
        "config_path = \"./config.yaml\"\n",
        "\n",
        "with open(config_path, \"r\") as file:\n",
        "    loaded_config = yaml.safe_load(file)\n",
        "\n",
        "# 불러온 config 파일의 전체 내용을 확인합니다.\n",
        "pprint(loaded_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xRSbKEVslhwO",
        "outputId": "14aba3e0-2764-4465-8b40-8c140f07a28d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data_path': '../data_en/',\n",
              " 'model_name': 'google/pegasus-xsum',\n",
              " 'output_dir': './'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 실험에 쓰일 데이터의 경로, 사용될 모델, 모델의 최종 출력 결과를 저장할 경로에 대해 확인합니다.\n",
        "loaded_config['general']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wyry1f8brKUX"
      },
      "outputs": [],
      "source": [
        "# 이곳에 사용자가 저장한 데이터 dir 설정하기\n",
        "# loaded_config['general']['data_path'] = \"data_path\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1pvFmIOqljv1",
        "outputId": "f5876ac2-d340-4db5-d2eb-dac59b650e43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bos_token': 'None',\n",
              " 'decoder_max_len': 100,\n",
              " 'encoder_max_len': 512,\n",
              " 'eos_token': '</s>',\n",
              " 'special_tokens': ['#Person1#',\n",
              "  '#Person2#',\n",
              "  '#Person3#',\n",
              "  '#PhoneNumber#',\n",
              "  '#Address#',\n",
              "  '#PassportNumber#',\n",
              "  '#DateOfBirth#',\n",
              "  '#SSN#',\n",
              "  '#CardNumber#',\n",
              "  '#CarNumber#',\n",
              "  '#Email#',\n",
              "  '#Person#',\n",
              "  '#Person4#',\n",
              "  '#Person5#',\n",
              "  '#Person6#',\n",
              "  '#Person7#']}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터 전처리를 하기 위해 tokenization 과정에서 필요한 정보들을 확인합니다.\n",
        "loaded_config['tokenizer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEvwCIBVll-h",
        "outputId": "180dae12-b9b4-4b21-dcca-329d2f4f239d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'do_eval': True,\n",
              " 'do_train': True,\n",
              " 'early_stopping_patience': 5,\n",
              " 'early_stopping_threshold': 0,\n",
              " 'evaluation_strategy': 'epoch',\n",
              " 'fp16': True,\n",
              " 'generation_max_length': 100,\n",
              " 'gradient_accumulation_steps': 6,\n",
              " 'learning_rate': 1e-05,\n",
              " 'load_best_model_at_end': True,\n",
              " 'logging_dir': './logs',\n",
              " 'logging_strategy': 'epoch',\n",
              " 'lr_scheduler_type': 'cosine',\n",
              " 'num_train_epochs': 20,\n",
              " 'optim': 'adamw_torch',\n",
              " 'overwrite_output_dir': True,\n",
              " 'per_device_eval_batch_size': 32,\n",
              " 'per_device_train_batch_size': 16,\n",
              " 'predict_with_generate': True,\n",
              " 'report_to': 'wandb',\n",
              " 'save_strategy': 'epoch',\n",
              " 'save_total_limit': 5,\n",
              " 'seed': 42,\n",
              " 'warmup_ratio': 0.1,\n",
              " 'weight_decay': 0.01}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델이 훈련 시 적용될 매개변수를 확인합니다.\n",
        "loaded_config['training']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhqHf1njlnyg",
        "outputId": "d372c951-e6e4-4ed2-acc2-177ab9bba2a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'entity': 'upstage6_doc_classification',\n",
              " 'name': 'nlp',\n",
              " 'project': 'baseline_Pegasus'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 학습 과정에 대한 정보를 제공해주는 wandb 설정 내용을 확인합니다.\n",
        "loaded_config['wandb']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "REV6GsQarKUX"
      },
      "outputs": [],
      "source": [
        "# (선택) 이곳에 사용자가 사용할 wandb config 설정\n",
        "# loaded_config['wandb']['entity'] = \"사용할 wandb repo name\"\n",
        "# loaded_config['wandb']['name'] = \"사용할 wandb run의 name\"\n",
        "# loaded_config['wandb']['project'] = \"사용할 wandb project name\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm4gxPRVlppj",
        "outputId": "c75aac94-7bfc-4421-9687-53c5d01d35a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch_size': 8,\n",
              " 'ckt_path': 'model ckt path',\n",
              " 'early_stopping': True,\n",
              " 'generate_max_length': 200,\n",
              " 'no_repeat_ngram_size': 2,\n",
              " 'num_beams': 4,\n",
              " 'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'],\n",
              " 'result_path': './prediction/'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델이 최종 결과를 출력하기 위한 매개변수 정보를 확인합니다.\n",
        "loaded_config['inference']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2zt0b-8ogCL"
      },
      "source": [
        "### 4) 데이터 불러와서 확인해보기\n",
        "- 실험에서 쓰일 데이터를 load하여 데이터의 구조와 내용을 살펴보겠습니다.\n",
        "- Train, dev, test 순서대로 12457, 499, 250개 씩 데이터가 구성되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "QFHIE2G04y-K",
        "outputId": "ea276d53-af44-473c-f89d-c606a212d048"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12455</th>\n",
              "      <td>train_12455</td>\n",
              "      <td>#Person1#: Excuse me. You are Mr. Green from M...</td>\n",
              "      <td>Tan Ling picks Mr. Green up who is easily reco...</td>\n",
              "      <td>pick up someone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12456</th>\n",
              "      <td>train_12456</td>\n",
              "      <td>#Person1#: Mister Ewing said we should show up...</td>\n",
              "      <td>#Person1# and #Person2# plan to take the under...</td>\n",
              "      <td>conference center</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12457</th>\n",
              "      <td>train_12457</td>\n",
              "      <td>#Person1#: How can I help you today?\\n#Person2...</td>\n",
              "      <td>#Person2# rents a small car for 5 days with th...</td>\n",
              "      <td>rent a car</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12458</th>\n",
              "      <td>train_12458</td>\n",
              "      <td>#Person1#: You look a bit unhappy today. What'...</td>\n",
              "      <td>#Person2#'s mom lost her job. #Person2# hopes ...</td>\n",
              "      <td>job losing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459</th>\n",
              "      <td>train_12459</td>\n",
              "      <td>#Person1#: Mom, I'm flying to visit uncle Lee'...</td>\n",
              "      <td>#Person1# asks for #Person2#'s idea of packing...</td>\n",
              "      <td>baggage pack</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id                                           dialogue  \\\n",
              "12455  train_12455  #Person1#: Excuse me. You are Mr. Green from M...   \n",
              "12456  train_12456  #Person1#: Mister Ewing said we should show up...   \n",
              "12457  train_12457  #Person1#: How can I help you today?\\n#Person2...   \n",
              "12458  train_12458  #Person1#: You look a bit unhappy today. What'...   \n",
              "12459  train_12459  #Person1#: Mom, I'm flying to visit uncle Lee'...   \n",
              "\n",
              "                                                 summary              topic  \n",
              "12455  Tan Ling picks Mr. Green up who is easily reco...    pick up someone  \n",
              "12456  #Person1# and #Person2# plan to take the under...  conference center  \n",
              "12457  #Person2# rents a small car for 5 days with th...         rent a car  \n",
              "12458  #Person2#'s mom lost her job. #Person2# hopes ...         job losing  \n",
              "12459  #Person1# asks for #Person2#'s idea of packing...       baggage pack  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
        "data_path = loaded_config['general']['data_path']\n",
        "\n",
        "# train data의 구조와 내용을 확인합니다.\n",
        "train_df = pd.read_csv(os.path.join(data_path,'train_en.csv'))\n",
        "train_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "FAGaYvNZ09Sq",
        "outputId": "cc0ae6d8-a688-4c88-aa8f-d7c4333af561"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>dev_495</td>\n",
              "      <td>#Person1#: Now that it's the new year, I've de...</td>\n",
              "      <td>#Person1# decides to stop smoking and come out...</td>\n",
              "      <td>the new year</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>dev_496</td>\n",
              "      <td>#Person1#: You married Joe, didn't you? \\n#Per...</td>\n",
              "      <td>#Person1# thought #Person2# married Joe. #Pers...</td>\n",
              "      <td>fall in love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>dev_497</td>\n",
              "      <td>#Person1#: How can I help you mam?\\n#Person2#:...</td>\n",
              "      <td>#Person2#'s car makes noises. #Person1# thinks...</td>\n",
              "      <td>noises</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>dev_498</td>\n",
              "      <td>#Person1#: Hello, Amazon's customer service. H...</td>\n",
              "      <td>#Person2# calls Amazon's customer service beca...</td>\n",
              "      <td>a missing page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>dev_499</td>\n",
              "      <td>#Person1#: I can't believe it's almost summer....</td>\n",
              "      <td>#Person2# tells #Person1# #Person2# is going t...</td>\n",
              "      <td>summer vacation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                           dialogue  \\\n",
              "495  dev_495  #Person1#: Now that it's the new year, I've de...   \n",
              "496  dev_496  #Person1#: You married Joe, didn't you? \\n#Per...   \n",
              "497  dev_497  #Person1#: How can I help you mam?\\n#Person2#:...   \n",
              "498  dev_498  #Person1#: Hello, Amazon's customer service. H...   \n",
              "499  dev_499  #Person1#: I can't believe it's almost summer....   \n",
              "\n",
              "                                               summary            topic  \n",
              "495  #Person1# decides to stop smoking and come out...     the new year  \n",
              "496  #Person1# thought #Person2# married Joe. #Pers...     fall in love  \n",
              "497  #Person2#'s car makes noises. #Person1# thinks...           noises  \n",
              "498  #Person2# calls Amazon's customer service beca...   a missing page  \n",
              "499  #Person2# tells #Person1# #Person2# is going t...  summer vacation  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# validation data의 구조와 내용을 확인합니다.\n",
        "val_df = pd.read_csv(os.path.join(data_path,'validation_en.csv'))\n",
        "val_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>test_498_2</td>\n",
              "      <td>#Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...</td>\n",
              "      <td>Matthew and Steve meet after a long time. Stev...</td>\n",
              "      <td>finding a house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>test_498_3</td>\n",
              "      <td>#Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...</td>\n",
              "      <td>Steve has been looking for a place to live. Ma...</td>\n",
              "      <td>find a house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>test_499_1</td>\n",
              "      <td>#Person1#: Hey, Betsy, did you hear the great ...</td>\n",
              "      <td>Frank invites Besty to the party to celebrate ...</td>\n",
              "      <td>party invitation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>test_499_2</td>\n",
              "      <td>#Person1#: Hey, Betsy, did you hear the great ...</td>\n",
              "      <td>Frank invites Betsy to the big promotion party...</td>\n",
              "      <td>promotion party invitation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>test_499_3</td>\n",
              "      <td>#Person1#: Hey, Betsy, did you hear the great ...</td>\n",
              "      <td>Frank invites Betsy to his party for his promo...</td>\n",
              "      <td>party invitation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id                                           dialogue  \\\n",
              "1495  test_498_2  #Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...   \n",
              "1496  test_498_3  #Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...   \n",
              "1497  test_499_1  #Person1#: Hey, Betsy, did you hear the great ...   \n",
              "1498  test_499_2  #Person1#: Hey, Betsy, did you hear the great ...   \n",
              "1499  test_499_3  #Person1#: Hey, Betsy, did you hear the great ...   \n",
              "\n",
              "                                                summary  \\\n",
              "1495  Matthew and Steve meet after a long time. Stev...   \n",
              "1496  Steve has been looking for a place to live. Ma...   \n",
              "1497  Frank invites Besty to the party to celebrate ...   \n",
              "1498  Frank invites Betsy to the big promotion party...   \n",
              "1499  Frank invites Betsy to his party for his promo...   \n",
              "\n",
              "                           topic  \n",
              "1495             finding a house  \n",
              "1496                find a house  \n",
              "1497            party invitation  \n",
              "1498  promotion party invitation  \n",
              "1499            party invitation  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test data의 구조와 내용을 확인합니다.\n",
        "test_df = pd.read_csv(os.path.join(data_path,'test_en.csv'))\n",
        "test_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IIaIrpH4kWo"
      },
      "source": [
        "## 1. 데이터 가공 및 데이터셋 클래스 구축\n",
        "- csv file 을 불러와서 encoder 와 decoder의 입력형태로 가공해줍니다.\n",
        "- 가공된 데이터를 torch dataset class 로 구축하여 모델에 입력가능한 형태로 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oWPawUUflwHa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "class Preprocess:\n",
        "    def __init__(self,\n",
        "            bos_token: str,\n",
        "            eos_token: str,\n",
        "        ) -> None:\n",
        "\n",
        "        self.bos_token = bos_token\n",
        "        self.eos_token = eos_token\n",
        "\n",
        "    @staticmethod\n",
        "    # 실험에 필요한 컬럼을 가져옵니다.\n",
        "    def make_set_as_df(file_path, is_train=True):\n",
        "        df = pd.read_csv(file_path)\n",
        "        if is_train:\n",
        "            return df[['id', 'dialogue', 'summary']]\n",
        "        else:\n",
        "            return df[['id', 'dialogue']]\n",
        "\n",
        "    # Pegasus 모델의 입력, 출력 형태를 맞추기 위해 전처리를 진행합니다.\n",
        "    def make_input(self, dataset, is_train=True):\n",
        "        prefix = \"summarize: \"\n",
        "        \n",
        "        # 인코더 입력을 처리합니다.\n",
        "        encoder_input = dataset['dialogue'].apply(lambda x: prefix + str(x))\n",
        "\n",
        "        if is_train:\n",
        "            # 디코더 입력: BOS + summary\n",
        "            decoder_input = dataset['summary'].apply(lambda x: self.bos_token + \" \" + str(x))\n",
        "            \n",
        "            # 디코더 출력: summary + EOS\n",
        "            decoder_output = dataset['summary'].apply(lambda x: str(x) + self.eos_token)\n",
        "            \n",
        "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()\n",
        "        else:\n",
        "            # 테스트 데이터인 경우 디코더 입력에 BOS만 넣어줍니다.\n",
        "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
        "            return encoder_input.tolist(), list(decoder_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6GDvodoF8sED"
      },
      "outputs": [],
      "source": [
        "# Train에 사용되는 Dataset 클래스를 정의합니다.\n",
        "class DatasetForTrain(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input, labels): # len 삭제 후 \n",
        "        self.encoder_input = encoder_input\n",
        "        self.decoder_input = decoder_input\n",
        "        self.labels = labels\n",
        "        self.len = len(encoder_input['input_ids']) # 데이터 길이 자동 계산\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 인코더 인풋 처리 \n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} \n",
        "        # 디코더 인풋 처리 \n",
        "        item['decoder_input_ids'] = item['input_ids']\n",
        "        # labels 처리 (보통 인코더 인풋과 같거나 일부 padding 값을 -100으로 설정)\n",
        "        labels=self.labels['input_ids'][idx].clone().detach()\n",
        "        labels[labels == 0] = -100 # 패딩 값 무시 \n",
        "        item['labels'] = labels \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# Validation에 사용되는 Dataset 클래스를 정의합니다.\n",
        "class DatasetForVal(Dataset):\n",
        "    def __init__(self, encoder_input, labels):\n",
        "        self.encoder_input = encoder_input\n",
        "        # 학습처럼 decoder_input_ids는 필요 없음\n",
        "        self.labels = labels\n",
        "        self.len = len(encoder_input['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} \n",
        "        labels=self.labels['input_ids'][idx].clone().detach()\n",
        "        labels[labels == 0] = -100 # 패딩 값 무시 \n",
        "        item['labels'] = labels\n",
        "        \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# Test에 사용되는 Dataset 클래스를 정의합니다.\n",
        "class DatasetForInference(Dataset):\n",
        "    def __init__(self, encoder_input):\n",
        "        self.encoder_input = encoder_input\n",
        "        self.len = len(encoder_input['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Encoder Input 처리\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
        "        \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hT9z4vvS2CCb"
      },
      "outputs": [],
      "source": [
        "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
        "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
        "    train_file_path = os.path.join(data_path, 'train_en.csv')\n",
        "    val_file_path = os.path.join(data_path, 'validation_en.csv')\n",
        "\n",
        "    # train, validation에 대해 각각 데이터프레임을 구축합니다.\n",
        "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
        "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
        "\n",
        "    # 인코더와 디코더 입력 및 출력을 생성합니다.\n",
        "    encoder_input_train, decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
        "    encoder_input_val, decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
        "\n",
        "    # Train 데이터셋의 Tokenization\n",
        "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
        "                                         truncation=True, max_length=config['tokenizer']['encoder_max_len'])\n",
        "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
        "                                         truncation=True, max_length=config['tokenizer']['decoder_max_len'])\n",
        "    tokenized_decoder_outputs = tokenizer(text_target=decoder_output_train, return_tensors=\"pt\", padding=True,\n",
        "                                          truncation=True, max_length=config['tokenizer']['decoder_max_len'])\n",
        "\n",
        "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_outputs, len(encoder_input_train))\n",
        "\n",
        "    # Validation 데이터셋의 Tokenization (decoder_input 없이 처리)\n",
        "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
        "                                             truncation=True, max_length=config['tokenizer']['encoder_max_len'])\n",
        "    val_tokenized_decoder_outputs = tokenizer(text_target=decoder_output_val, return_tensors=\"pt\", padding=True,\n",
        "                                              truncation=True, max_length=config['tokenizer']['decoder_max_len'])\n",
        "\n",
        "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_outputs)\n",
        "\n",
        "    return train_inputs_dataset, val_inputs_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5sKIJ5K5Pz1"
      },
      "source": [
        "## 2. Trainer 및 Trainingargs 구축하기\n",
        "- Huggingface 의 Trainer 와 Training arguments를 활용하여 모델 학습을 일괄적으로 처리해주는 클래스를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aQk8ILcEeGNz"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "# from rouge import Rouge\n",
        "\n",
        "def compute_metrics(config, tokenizer, pred):\n",
        "    rouge = Rouge()\n",
        "    predictions = pred.predictions\n",
        "    labels = pred.label_ids\n",
        "\n",
        "    # 패딩 토큰으로 대체\n",
        "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
        "    labels[labels == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # 디코딩된 예측값과 레이블\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    # 불필요한 생성 토큰 제거\n",
        "    remove_tokens = config['inference']['remove_tokens']\n",
        "    replaced_predictions = decoded_preds.copy()\n",
        "    replaced_labels = decoded_labels.copy()\n",
        "    \n",
        "    for token in remove_tokens:\n",
        "        # 정규식을 사용하여 여러 경우의 불필요한 토큰을 처리\n",
        "        replaced_predictions = [re.sub(rf\"\\b{token}\\b\", \" \", sentence) for sentence in replaced_predictions]\n",
        "        replaced_labels = [re.sub(rf\"\\b{token}\\b\", \" \", sentence) for sentence in replaced_labels]\n",
        "\n",
        "    # 중복된 공백 제거\n",
        "    replaced_predictions = [\" \".join(sentence.split()) for sentence in replaced_predictions]\n",
        "    replaced_labels = [\" \".join(sentence.split()) for sentence in replaced_labels]\n",
        "\n",
        "    # 디버깅용 출력 (필요 시 로깅으로 교체 가능)\n",
        "    print('-'*150)\n",
        "    print(f\"PRED: {replaced_predictions[0]}\")\n",
        "    print(f\"GOLD: {replaced_labels[0]}\")\n",
        "    print('-'*150)\n",
        "    print(f\"PRED: {replaced_predictions[1]}\")\n",
        "    print(f\"GOLD: {replaced_labels[1]}\")\n",
        "    print('-'*150)\n",
        "    print(f\"PRED: {replaced_predictions[2]}\")\n",
        "    print(f\"GOLD: {replaced_labels[2]}\")\n",
        "\n",
        "    # ROUGE 점수 계산\n",
        "    results = rouge.get_scores(replaced_predictions, replaced_labels, avg=True)\n",
        "\n",
        "    # F1-score를 사용하여 평가\n",
        "    result = {key: value[\"f\"] for key, value in results.items()}\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RInkG8g-HjBi"
      },
      "outputs": [],
      "source": [
        "# 학습을 위한 trainer 클래스와 매개변수를 정의합니다.\n",
        "def load_trainer_for_train(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset):\n",
        "    print('-'*10, 'Make training arguments', '-'*10,)\n",
        "    # set training args\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "                output_dir=config['general']['output_dir'], # model output directory\n",
        "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
        "                num_train_epochs=config['training']['num_train_epochs'],  # total number of training epochs\n",
        "                learning_rate=config['training']['learning_rate'], # learning_rate\n",
        "                per_device_train_batch_size=config['training']['per_device_train_batch_size'], # batch size per device during training\n",
        "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],# batch size for evaluation\n",
        "                warmup_ratio=config['training']['warmup_ratio'],  # number of warmup steps for learning rate scheduler\n",
        "                weight_decay=config['training']['weight_decay'],  # strength of weight decay\n",
        "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
        "                optim =config['training']['optim'],\n",
        "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
        "                evaluation_strategy=config['training']['evaluation_strategy'], # evaluation strategy to adopt during training\n",
        "                save_strategy =config['training']['save_strategy'],\n",
        "                save_total_limit=config['training']['save_total_limit'], # number of total save model.\n",
        "                fp16=config['training']['fp16'],\n",
        "                load_best_model_at_end=config['training']['load_best_model_at_end'], # 최종적으로 가장 높은 점수 저장\n",
        "                seed=config['training']['seed'],\n",
        "                logging_dir=config['training']['logging_dir'], # directory for storing logs\n",
        "                logging_strategy=config['training']['logging_strategy'],\n",
        "                predict_with_generate=config['training']['predict_with_generate'], #To use BLEU or ROUGE score\n",
        "                generation_max_length=config['training']['generation_max_length'],\n",
        "                do_train=config['training']['do_train'],\n",
        "                do_eval=config['training']['do_eval'],\n",
        "                report_to=config['training']['report_to'] # (선택) wandb를 사용할 때 설정합니다.\n",
        "            )\n",
        "\n",
        "    # (선택) 모델의 학습 과정을 추적하는 wandb를 사용하기 위해 초기화 해줍니다.\n",
        "    wandb.init(\n",
        "        entity=config['wandb']['entity'],\n",
        "        project=config['wandb']['project'],\n",
        "        name=config['wandb']['name'],\n",
        "    )\n",
        "\n",
        "    # (선택) 모델 checkpoint를 wandb에 저장하도록 환경 변수를 설정합니다.\n",
        "    os.environ[\"WANDB_LOG_MODEL\"]=\"end\"\n",
        "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
        "    \n",
        "    # Validation loss가 더 이상 개선되지 않을 때 학습을 중단시키는 EarlyStopping 기능을 사용합니다.\n",
        "    MyCallback = EarlyStoppingCallback(\n",
        "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
        "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
        "    )\n",
        "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
        "    print('-'*10, 'Make trainer', '-'*10,)\n",
        "\n",
        "    # Trainer 클래스를 정의합니다.\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=generate_model, # 사용자가 사전 학습하기 위해 사용할 모델을 입력합니다.\n",
        "        args=training_args,\n",
        "        train_dataset=train_inputs_dataset,\n",
        "        eval_dataset=val_inputs_dataset,\n",
        "        compute_metrics = lambda pred: compute_metrics(config, tokenizer, pred),\n",
        "        callbacks = [MyCallback]\n",
        "    )\n",
        "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
        "\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KKWHe8dE5fSx"
      },
      "outputs": [],
      "source": [
        "# 학습을 위한 tokenizer와 사전 학습된 모델을 불러옵니다.\n",
        "def load_tokenizer_and_model_for_train(config, device):\n",
        "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
        "    print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
        "\n",
        "    # 모델 및 토크나이저 이름 \n",
        "    model_name = config['general']['model_name']\n",
        "\n",
        "    # 모델 설정 불러오기\n",
        "    model_config = PegasusConfig.from_pretrained(model_name)\n",
        "\n",
        "    # 토크나이저 불러오기\n",
        "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Special tokens 추가 \n",
        "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
        "    tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "    # 사전 학습된 모델 불러오기 및 설정 적용\n",
        "    generate_model = PegasusForConditionalGeneration.from_pretrained(config['general']['model_name'], config=model_config)\n",
        "    \n",
        "    # 토크나이저에 새로운 토큰이 추가되었으므로 임베딩 크기 재조정 \n",
        "    generate_model.resize_token_embeddings(len(tokenizer)) \n",
        "\n",
        "    # GPU or CPU\n",
        "    generate_model.to(device)\n",
        "\n",
        "    # 모델 구성 정보 출력\n",
        "    print('-'*10,'Model Configuration','-'*10)\n",
        "    print(generate_model.config)\n",
        "\n",
        "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
        "    return generate_model , tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvutzKQYvQgl"
      },
      "source": [
        "## 3. 모델 학습하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImZUb-BC42J-"
      },
      "source": [
        "- 앞에서 구축한 클래스 및 함수를 활용하여 학습 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qnA96wmR44is"
      },
      "outputs": [],
      "source": [
        "def main(config):\n",
        "    try:\n",
        "        # 사용할 device를 정의합니다.\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
        "        print('-'*10, f'device : {device}', '-'*10,)\n",
        "        print(torch.__version__)\n",
        "\n",
        "        # 사용할 모델과 tokenizer를 불러옵니다.\n",
        "        generate_model, tokenizer = load_tokenizer_and_model_for_train(config, device)\n",
        "        print('-'*10,\"tokenizer special tokens : \", tokenizer.special_tokens_map,'-'*10)\n",
        "        print('-'*10,\"additional special tokens : \", tokenizer.additional_special_tokens, tokenizer.additional_special_tokens_ids)\n",
        "\n",
        "        # 학습에 사용할 데이터셋을 불러옵니다.\n",
        "        preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
        "        data_path = config['general']['data_path']\n",
        "        train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config, preprocessor, data_path, tokenizer)\n",
        "\n",
        "        # # Clear the cache to free up GPU memory\n",
        "        # torch.cuda.empty_cache()\n",
        "\n",
        "        # Trainer 클래스를 불러옵니다.\n",
        "        trainer = load_trainer_for_train(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset)\n",
        "        trainer.train()   # 모델 학습을 시작합니다.\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training:{e}\")\n",
        "    finally: \n",
        "        print('-'*10,'Training finished.CLosing WandB session','-'*10)\n",
        "\n",
        "    # (선택) 모델 학습이 완료된 후 wandb를 종료합니다.\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1DMS60wL-Dhv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- device : cuda:0 ----------\n",
            "2.4.1+cu121\n",
            "---------- Load tokenizer & model ----------\n",
            "---------- Model Name : google/pegasus-xsum ----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbda6f43da7a4c428a55ab48003ef974",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc6a502632bc481d943dd0f5b432801d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- Model Configuration ----------\n",
            "PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-xsum\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 0,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.6,\n",
            "  \"max_length\": 64,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96119\n",
            "}\n",
            "\n",
            "---------- Load tokenizer & model complete ----------\n",
            "---------- tokenizer special tokens :  {'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask_2>', 'additional_special_tokens': ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#', '#DateOfBirth#', '#SSN#', '#CardNumber#', '#CarNumber#', '#Email#', '#Person#', '#Person4#', '#Person5#', '#Person6#', '#Person7#']} ----------\n",
            "---------- additional special tokens :  ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#', '#DateOfBirth#', '#SSN#', '#CardNumber#', '#CarNumber#', '#Email#', '#Person#', '#Person4#', '#Person5#', '#Person6#', '#Person7#'] [96103, 96104, 96105, 96106, 96107, 96108, 96109, 96110, 96111, 96112, 96113, 96114, 96115, 96116, 96117, 96118]\n",
            "Error during training:DatasetForTrain.__init__() takes 4 positional arguments but 5 were given\n",
            "---------- Training finished.CLosing WandB session ----------\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main(loaded_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFtWqowCGzEc"
      },
      "source": [
        "## 4. 모델 추론하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEDwgCnarKUZ"
      },
      "outputs": [],
      "source": [
        "# 추론에 사용할 ckt 경로 설정\n",
        "loaded_config['inference']['ckt_path'] = \"checkpoint-22837\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFGul3-rSscf"
      },
      "source": [
        "- test data를 사용하여 모델의 성능을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV1Do7nlTylG"
      },
      "outputs": [],
      "source": [
        "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
        "def prepare_test_dataset(config, preprocessor, tokenizer):\n",
        "\n",
        "    test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
        "\n",
        "    test_data = preprocessor.make_set_as_df(test_file_path, is_train=False)\n",
        "    test_id = test_data['fname']\n",
        "\n",
        "    print('-'*150)\n",
        "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
        "    print('-'*150)\n",
        "\n",
        "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data, is_test=True)\n",
        "    print('-'*10, 'Load data complete', '-'*10,)\n",
        "\n",
        "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
        "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
        "    \n",
        "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
        "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
        "\n",
        "    return test_data, test_encoder_inputs_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb49bLULT3aS"
      },
      "outputs": [],
      "source": [
        "# 추론을 위한 tokenizer와 학습시킨 모델을 불러옵니다.\n",
        "def load_tokenizer_and_model_for_test(config, device):\n",
        "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
        "\n",
        "    model_name = config['general']['model_name']\n",
        "    ckt_path = config['inference']['ckt_path']\n",
        "    print('-'*10, f'Model Name : {model_name}', '-'*10,)\n",
        "\n",
        "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
        "    tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "    generate_model = PegasusForConditionalGeneration.from_pretrained(ckt_path)\n",
        "    generate_model.resize_token_embeddings(len(tokenizer))\n",
        "    generate_model.to(device)\n",
        "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
        "\n",
        "    return generate_model , tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axzu9rsoGLgJ"
      },
      "outputs": [],
      "source": [
        "# 학습된 모델이 생성한 요약문의 출력 결과를 보여줍니다.\n",
        "def inference(config):\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
        "    print('-'*10, f'device : {device}', '-'*10,)\n",
        "    print(torch.__version__)\n",
        "\n",
        "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
        "\n",
        "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
        "\n",
        "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config, preprocessor, tokenizer)\n",
        "   \n",
        "    batch_size=config['inference']['batch_size']\n",
        "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=batch_size)\n",
        "\n",
        "    summary = []\n",
        "    text_ids = []\n",
        "    with torch.no_grad():\n",
        "        for item in tqdm(dataloader):\n",
        "            text_ids.extend(item['ID'])\n",
        "            generated_ids = generate_model.generate(\n",
        "                input_ids=item['input_ids'].to('cuda:0'),\n",
        "                no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
        "                early_stopping=config['inference']['early_stopping'],\n",
        "                max_length=config['inference']['generate_max_length'],\n",
        "                num_beams=config['inference']['num_beams'],\n",
        "            )\n",
        "            for ids in generated_ids:\n",
        "                result = tokenizer.decode(ids,skip_special_tokens=True)\n",
        "                summary.append(result)\n",
        "\n",
        "    # 정확한 평가를 위하여 노이즈에 해당되는 스페셜 토큰을 제거합니다.\n",
        "    # remove_tokens = config['inference']['remove_tokens']\n",
        "    # preprocessed_summary = summary.copy()\n",
        "    # for token in remove_tokens:\n",
        "    #     preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
        "\n",
        "    output = pd.DataFrame(\n",
        "        {\n",
        "            \"fname\": test_data['fname'],\n",
        "            \"summary\" : summary,\n",
        "        }\n",
        "    )\n",
        "    result_path = config['inference']['result_path']\n",
        "    if not os.path.exists(result_path):\n",
        "        os.makedirs(result_path)\n",
        "    output.to_csv(os.path.join(result_path, \"output_pegasus_en.csv\"), index=False)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pJ1ZXf-5V50",
        "outputId": "ec7f63de-7fc0-4911-cf29-df4c2ae48cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- device : cuda:0 ----------\n",
            "2.1.0\n",
            "---------- Load tokenizer & model ----------\n",
            "---------- Model Name : lcw99/t5-large-korean-text-summary ----------\n",
            "---------- Load tokenizer & model complete ----------\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "test_data:\n",
            "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
            "#Person2#: 네, 실장님...\n",
            "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
            "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
            "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
            "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
            "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
            "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
            "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
            "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
            "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
            "#Person2#: 그게 다신가요?\n",
            "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "---------- Load data complete ----------\n",
            "---------- Make dataset complete ----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [04:40<00:00,  2.25s/it]\n"
          ]
        }
      ],
      "source": [
        "# 학습된 모델의 test를 진행합니다.\n",
        "if __name__ == \"__main__\":\n",
        "    output = inference(loaded_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsPmLfhbzZqS",
        "outputId": "fd4a2aaf-592a-47a7-95f4-402fcf08882f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>#Person1#은 모든 직원들에게 즉시 메시지 프로그램을 사용하지 않도록 주의하...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>#Person2#는 교통 체증에 걸렸다. #Person1#은 대중교통을 이용하는 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>#Person1#은 #Person2#에게 마샤와 히어로가 이혼을 신청했다고 말한다...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>#Person1#은 브라이언의 생일 파티에 참석하고 그와 춤을 추며 축하한다.  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>#Person2#는 #Person1#에게 올림픽 스타디움이 6월에 완공될 예정이며...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>test_495</td>\n",
              "      <td>잭은 찰리에게 비디오 게임을 하자고 제안한다. 찰리는 그것이 흥미롭다고 생각하고 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>test_496</td>\n",
              "      <td>#Person2#는 #Person1#에게 컨트리 음악에 관심을 가지게 된 계기와 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>test_497</td>\n",
              "      <td>앨리스는 #Person1#에게 세탁기와 건조기를 어떻게 사용하는지 알려주고, 기계...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>test_498</td>\n",
              "      <td>스티브가 매튜에게 최근에 살 곳을 찾고 있다고 말한다. 그들은 함께 다우 부인의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>test_499</td>\n",
              "      <td>프랭크는 승진 파티에 벳시를 초대하고 그들은 참석할 예정이다. 프랭크은 가족과의 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>499 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        fname                                            summary\n",
              "0      test_0   #Person1#은 모든 직원들에게 즉시 메시지 프로그램을 사용하지 않도록 주의하...\n",
              "1      test_1   #Person2#는 교통 체증에 걸렸다. #Person1#은 대중교통을 이용하는 ...\n",
              "2      test_2   #Person1#은 #Person2#에게 마샤와 히어로가 이혼을 신청했다고 말한다...\n",
              "3      test_3   #Person1#은 브라이언의 생일 파티에 참석하고 그와 춤을 추며 축하한다.  ...\n",
              "4      test_4   #Person2#는 #Person1#에게 올림픽 스타디움이 6월에 완공될 예정이며...\n",
              "..        ...                                                ...\n",
              "494  test_495   잭은 찰리에게 비디오 게임을 하자고 제안한다. 찰리는 그것이 흥미롭다고 생각하고 ...\n",
              "495  test_496   #Person2#는 #Person1#에게 컨트리 음악에 관심을 가지게 된 계기와 ...\n",
              "496  test_497   앨리스는 #Person1#에게 세탁기와 건조기를 어떻게 사용하는지 알려주고, 기계...\n",
              "497  test_498   스티브가 매튜에게 최근에 살 곳을 찾고 있다고 말한다. 그들은 함께 다우 부인의 ...\n",
              "498  test_499   프랭크는 승진 파티에 벳시를 초대하고 그들은 참석할 예정이다. 프랭크은 가족과의 ...\n",
              "\n",
              "[499 rows x 2 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output  # 각 대화문에 대한 요약문이 출력됨을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf6Ospc7rKUc",
        "outputId": "e9efb961-c048-447d-867e-69a6f1f72c0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(output['summary'][0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
